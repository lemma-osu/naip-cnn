{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01: Sampling\n",
    "\n",
    "This notebook locates and samples plots, exporting an HDF5 dataset with arrays of LiDAR metrics and NAIP reflectance values for each plot footprint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "\n",
    "from naip_cnn import sampling\n",
    "from naip_cnn.acquisitions import (\n",
    "    MAL2007,\n",
    "    MAL2008_CampCreek,\n",
    "    MAL2008_2009_MalheurRiver,\n",
    "    MAL2010,\n",
    "    MAL2014,\n",
    "    MAL2016_CanyonCreek,\n",
    "    MAL2017_Crow,\n",
    "    MAL2017_JohnDay,\n",
    "    MAL2018_Aldrich_UpperBear,\n",
    "    MAL2018_Rattlesnake,\n",
    "    MAL2019,\n",
    "    MAL2020_UpperJohnDay,\n",
    ")\n",
    "from naip_cnn.data import NAIPDatasetWrapper\n",
    "\n",
    "# If you are not authenticated locally, run `ee.Authenticate()` first.\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "Our training data will be a set of points with 1) LiDAR attributes for prediction and 2) corresponding NAIP reflectance values. Both will ultimately be stored as co-located 2D arrays of pixel values at footprint locations. \n",
    "\n",
    "The first step will be to create a `NAIPDatasetWrapper` that will allow us to access LiDAR and NAIP data, as well as store relevant metadata such as the spatial resolution and sample footprint size in meters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = NAIPDatasetWrapper(\n",
    "    acquisitions=[MAL2019],\n",
    "    footprint=(30, 30),\n",
    "    naip_res=1.0,\n",
    "    lidar_res=30.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the acquisition and resolution parameters defined above, we can load coincident `ee.Image` mosaics of LiDAR and NAIP data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lidar = dataset.load_lidar()\n",
    "naip = dataset.load_naip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Sample Footprints\n",
    "\n",
    "We'll extract data across a collection of footprints. To begin, we'll distribute points across the LiDAR image with a minimum spacing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = lidar.sample(\n",
    "    scale=dataset.spacing,\n",
    "    projection=dataset.acquisitions[0].proj,\n",
    "    # This is set to keep the total number of samples exportable, and may need to be\n",
    "    # adjusted based on the size of the LiDAR acquisition.\n",
    "    factor=0.08,\n",
    "    dropNulls=True,\n",
    "    geometries=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check `samples.size` to figure out how many non-masked pixels were sampled at the given spacing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples.size().getInfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll convert our collection of sample points to square footprints with a given size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "footprints = samples.map(\n",
    "    lambda p: sampling.point_to_footprint(\n",
    "        p, dims=dataset.footprint, proj=dataset.acquisitions[0].proj\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Pixel Values\n",
    "\n",
    "With our footprints defined, we can extract arrays of pixel values from the LiDAR and NAIP images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_lidar(footprint: ee.Feature):\n",
    "    return sampling.extract_values_at_footprint(\n",
    "        footprint, img=lidar, proj=dataset.acquisitions[0].proj, scale=dataset.lidar_res\n",
    "    )\n",
    "\n",
    "\n",
    "def extract_naip(footprint: ee.Feature):\n",
    "    return sampling.extract_values_at_footprint(\n",
    "        footprint, img=naip, proj=dataset.acquisitions[0].proj, scale=dataset.naip_res\n",
    "    )\n",
    "\n",
    "\n",
    "footprints = footprints.map(extract_lidar, opt_dropNulls=True).map(\n",
    "    extract_naip, opt_dropNulls=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to Drive\n",
    "\n",
    "Extracting large numbers of pixel values across footprints is memory- and time-intensive, so we'll need to export the data to Drive rather than directly accessing it client-side. This process can take a while, and progress can be monitored in the [task manager](https://code.earthengine.google.com/tasks).\n",
    "\n",
    "***Note**: Make sure you're authenticated with the correct Earth Engine account, as this will determine the Drive to which data is exported.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = ee.batch.Export.table.toDrive(\n",
    "    collection=footprints,\n",
    "    description=dataset.name,\n",
    ")\n",
    "\n",
    "task.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert CSV To HDF5\n",
    "\n",
    "*Once the export task is complete*, you'll need to download the resulting CSV file to local storage. \n",
    "\n",
    "The CSV format exported by Earth Engine is not optimized for training, so we'll need to convert it to an HDF5 file. In the process, we'll reshape the pixel arrays, which are currently stored as comma-separated strings, into 2D arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use Dask to parallelize the loading and processing steps. Creating a local Dask client will allow us to monitor progress in the Dask dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client()\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the CSV file as a deferred Dask dataframe. You'll see that it includes columns for each of the NAIP bands, LiDAR attributes, and a few other metadata columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dd.read_csv(\"../\" + dataset.csv_path.as_posix())\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll parse the 1D strings into 2D arrays. We'll stack the NAIP arrays into a single `image` column, while each of the LiDAR labels will be kept in its own column, allowing us to easily train on a single label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"image\"] = df.apply(\n",
    "    sampling.parse_pixel_array,\n",
    "    shape=dataset.naip_shape,\n",
    "    col=(\"R\", \"G\", \"B\", \"N\"),\n",
    "    axis=1,\n",
    "    meta=pd.Series(dtype=np.uint8),\n",
    ")\n",
    "\n",
    "for label in (\"cover\", \"rh25\", \"rh50\", \"rh95\", \"rh100\"):\n",
    "    df[label] = df.apply(\n",
    "        sampling.parse_pixel_array,\n",
    "        shape=dataset.lidar_shape,\n",
    "        col=label,\n",
    "        axis=1,\n",
    "        meta=pd.Series(dtype=np.float32),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can drop the unused columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"R\", \"G\", \"B\", \"N\", \".geo\", \"height\", \"width\", \"system:index\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll load the entire dataframe into memory so that we can shuffle it, split it, and save it out to HDFs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.compute().sample(frac=1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into training, validation, and test sets. We do this now to avoid having to load the entire dataset into memory to properly shuffle during the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, holdout = train_test_split(df, train_size=0.8, random_state=42)\n",
    "val, test = train_test_split(holdout, train_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for split, split_df in ({\"train\": train, \"val\": val, \"test\": test}).items():\n",
    "    dst_path = (\n",
    "        \"../\"\n",
    "        + dataset.csv_path.with_name(\n",
    "            dataset.csv_path.stem + f\"_{split}\" + \".h5\"\n",
    "        ).as_posix()\n",
    "    )\n",
    "    with h5py.File(dst_path, \"w\") as f:\n",
    "        for var in (\"image\", \"cover\", \"rh25\", \"rh50\", \"rh95\", \"rh100\"):\n",
    "            f.create_dataset(\n",
    "                var, data=np.stack(split_df[var].values), compression=\"gzip\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to get an idea of the data we'll be training with, we can plot a few footprints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3\n",
    "check_footprints = train.sample(n=n, random_state=99)\n",
    "\n",
    "fig, ax = plt.subplots(n, 3, figsize=(6, n * 2))\n",
    "for i in range(n):\n",
    "    ax[i, 0].imshow(check_footprints[\"image\"].values[i][:, :, :3])\n",
    "    ax[i, 1].imshow(check_footprints[\"cover\"].values[i], vmin=0, vmax=100)\n",
    "    ax[i, 2].imshow(check_footprints[\"rh95\"].values[i], vmin=0, vmax=100)\n",
    "\n",
    "ax[0, 0].set_title(\"NAIP\")\n",
    "ax[0, 1].set_title(\"COVER\")\n",
    "ax[0, 2].set_title(\"RH95\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
